{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Veri Seti Hazırlama Süreci**\nBu betik, veri setini eğitim için hazırlamak amacıyla aşağıdaki adımları gerçekleştirir:\n\n1. **Veri Seti Dizini ve Sınıf Seçimi**\n* Veri Seti Dizinleri:\nGirdi, çıktı ve işlenmiş veri dizinlerini tanımlar.\n* Sınıf Seçimi:\nProjede kullanılacak hayvan sınıflarını belirler.\n\n2. **Görüntü Sınırları ve Ön İşleme Ayarları**\n* Sınıf Başına Görüntü Sınırı:\nHer sınıf için maksimum 650 görüntü ile sınırlandırır.\n* Görüntü Boyutlandırma:\nGörüntüleri yeniden boyutlandırmak için hedef boyutu (örneğin, 128x128 piksel) ayarlar.\n\n3. **Çıktı Dizinlerinin Kurulumu**\n* Mevcut Dizinlerin Temizlenmesi:\nÇıktı ve işlenmiş veri dizinlerini temizleyerek işlem öncesi temiz bir başlangıç sağlar.\n* Yeni Dizinlerin Oluşturulması:\nİşlenmiş görüntülerin kaydedilmesi için gerekli olan dizinleri yeniden oluşturur.\n\n4. **Görüntü Kopyalama ve İşleme**\n* Sınıflar Arasında Yineleme:\nBelirtilen hayvan sınıfları arasında döngü yapar.\n* Görüntülerin Çıktı Dizinine Kopyalanması:\nHer sınıf için belirtilen sınıra kadar olan görüntüleri çıktı dizinine kopyalar.\n* Görüntülerin İşlenmesi:\nGörüntüleri yeniden boyutlandırır ve normalleştirerek işlenmiş dizine kaydeder.","metadata":{}},{"cell_type":"code","source":"# Gerekli kütüphaneleri içe aktar\nimport cv2\nimport numpy as np\nimport os\nimport shutil\nfrom pathlib import Path\n\n# Veri seti dizinleri (Dosya yapınıza göre ayarlayın)\ndata_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\noutput_dir = \"/kaggle/working/selected_animals_dataset\"\nprocessed_dir = \"/kaggle/working/processed_dataset\"\n\n# Seçilen hayvan sınıfları\nselected_classes = [\n    \"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"\n]\n\n# Her sınıf için maksimum görüntü sayısı\nmax_images_per_class = 650\n\n# İstenen görüntü boyutu\nimage_size = (128, 128)  # Model girdi boyutuna göre ayarlanabilir\n\n# Çıktı ve işlenmiş dizinleri temizle ve yeniden oluştur\nif os.path.exists(output_dir):\n    shutil.rmtree(output_dir)\nos.makedirs(output_dir)\n\nif os.path.exists(processed_dir):\n    shutil.rmtree(processed_dir)\nos.makedirs(processed_dir)\n\n# Seçilen sınıfların görüntülerini kopyala ve işle\nfor animal_class in selected_classes:\n    class_path = os.path.join(data_dir, animal_class)\n    if os.path.exists(class_path):\n        images = sorted(os.listdir(class_path))[:max_images_per_class]\n        output_class_path = os.path.join(output_dir, animal_class)\n        processed_class_path = os.path.join(processed_dir, animal_class)\n        os.makedirs(output_class_path, exist_ok=True)\n        os.makedirs(processed_class_path, exist_ok=True)\n\n        for image in images:\n            source_path = os.path.join(class_path, image)\n            target_path = os.path.join(output_class_path, image)\n            shutil.copy2(source_path, target_path)\n\n            # Load image, resize and normalize\n            img = cv2.imread(source_path)\n            if img is not None:\n                img_resized = cv2.resize(img, image_size)\n                img_normalized = img_resized / 255.0\n                processed_image_path = os.path.join(processed_class_path, image)\n                cv2.imwrite(processed_image_path, (img_normalized * 255).astype(np.uint8))\n\nprint(f\"Selected classes and the first {max_images_per_class} images have been copied to '{output_dir}', and processed images saved to '{processed_dir}'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T14:19:43.285276Z","iopub.execute_input":"2024-12-20T14:19:43.285586Z","iopub.status.idle":"2024-12-20T14:21:11.232220Z","shell.execute_reply.started":"2024-12-20T14:19:43.285560Z","shell.execute_reply":"2024-12-20T14:21:11.230824Z"}},"outputs":[{"name":"stdout","text":"Selected classes and the first 650 images have been copied to '/kaggle/working/selected_animals_dataset', and processed images saved to '/kaggle/working/processed_dataset'.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **Eğitim ve Test Verilerinin Hazırlanması**\nBu betik, veri setini eğitim ve test için hazırlamak amacıyla aşağıdaki işlemleri gerçekleştirir:\n\n1. **Veri Seti ve Etiketlerin Tanımlanması**\n* İşlenmiş Veri Seti Dizini:\nİşlenmiş veri seti dizinini tanımlar.\n* Hayvan Sınıfları ve Etiketler:\nSeçilen hayvan sınıflarını listeler ve bu sınıfları sayısal etiketlere dönüştürür.\n\n2. **Veri Yükleme ve Normalizasyon**\n* Görüntülerin İşlenmesi:\nHer seçilen sınıf için işlenmiş görüntüler üzerinde iterasyon yapar.\n* Piksel Değerlerinin Normalizasyonu:\nGörüntülerin piksel değerlerini [0, 1] aralığına dönüştürür.\n\n3. **Verilerin Dönüştürülmesi**\n* NumPy Dönüşümü:\nGörüntü ve etiket listelerini modelle uyumlu hale getirmek için NumPy dizilerine dönüştürür.\n\n4. **Veri Setinin Bölünmesi**\n* Eğitim ve Test Ayrımı:\nVeri setini %70 eğitim ve %30 test olacak şekilde böler.\n* Rastgelelik Kontrolü:\nSabit bir rastgelelik tohumu kullanarak bölünmenin reproducible (tekrarlanabilir) olmasını sağlar.\n","metadata":{}},{"cell_type":"code","source":"# Gerekli Kütüphanelerin İçe Aktarılması\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# İşlenmiş Veri Seti Dizini\nprocessed_dir = \"/kaggle/working/processed_dataset\"\n\n# Seçilen Hayvan Sınıfları\nselected_classes = [\n    \"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"\n]\n\n# Veri ve Etiketlerin Hazırlanması\nX = []  # Images\ny = []  # Labels\nclass_mapping = {cls: idx for idx, cls in enumerate(selected_classes)}\n\n# Görüntülerin Yüklenmesi ve Normalize Edilmesi\nfor animal_class in selected_classes:\n    class_path = os.path.join(processed_dir, animal_class)\n    if os.path.exists(class_path):\n        images = sorted(os.listdir(class_path))\n\n        for image in images:\n            source_path = os.path.join(class_path, image)\n\n            # Load image and normalize (already resized)\n            img = cv2.imread(source_path)\n            if img is not None:\n                img_normalized = img / 255.0\n                X.append(img_normalized)\n                y.append(class_mapping[animal_class])\n\n# Verilerin NumPy Dizilerine Dönüştürülmesi\nX = np.array(X)\ny = np.array(y)\n\n# Veri Setinin Eğitim ve Test Olarak Ayrılması\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Bilgilendirme Çıktısı\nprint(f\"Data has been split into training and testing sets.\\nTrain size: {len(X_train)}, Test size: {len(X_test)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T14:21:23.796884Z","iopub.execute_input":"2024-12-20T14:21:23.797272Z","iopub.status.idle":"2024-12-20T14:21:31.476292Z","shell.execute_reply.started":"2024-12-20T14:21:23.797239Z","shell.execute_reply":"2024-12-20T14:21:31.475088Z"}},"outputs":[{"name":"stdout","text":"Data has been split into training and testing sets.\nTrain size: 4550, Test size: 1950\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# **Eğitim Verileri İçin Veri Artırımı (Data Augmentation)**\n1. **Veri Artırımı Başlatılması**\n* ImageDataGenerator sınıfının bir örneği, aşağıdaki veri artırımı seçenekleriyle oluşturulur:\n* **Döndürme (Rotation):** ±20 derece arasında rastgele döndürme.\n* **Yatay ve Dikey Kaydırma:** Görüntüleri toplam genişliğin veya yüksekliğin %20'si kadar rastgele kaydırma.\n* **Kesme Dönüşümleri (Shear Transformations):** Rastgele kesme dönüşümleri uygulanması.\n* **Yakınlaştırma (Zoom):** Görüntülere %20 oranında rastgele yakınlaştırma.\n* **Yatay Çevirme (Horizontal Flip):** Görüntüleri yatay eksende rastgele çevirme.\n* **Doldurma Modu (Fill Mode):** Dönüşümler sonrası oluşan boş piksellerin nasıl doldurulacağını belirtir.\n\n2. **Veri Artırımı Uygulanması**\n* Eğitim görüntüleri (X_train) ve bunlara karşılık gelen etiketler (y_train), 32 görüntülük partiler halinde artırılır.\n\n3. **Çıktı**\n* Eğitim verilerine veri artırımı işleminin başarıyla uygulandığı doğrulanır.","metadata":{}},{"cell_type":"code","source":"# Gerekli Kütüphanelerin İçe Aktarılması\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Eğitim Verilerine Veri Artırımı Uygulanması\naugmentation = ImageDataGenerator(\n    rotation_range=20,  # Rastgele döndürme\n    width_shift_range=0.2,  # Yatayda rastgele kaydırma\n    height_shift_range=0.2,  # Dikeyde rastgele kaydırma\n    shear_range=0.2,  # Kesme dönüşümleri\n    zoom_range=0.2,  # Rastgele yakınlaştırma\n    horizontal_flip=True,  # Rastgele yatay çevirme\n    fill_mode='nearest'  # Boş pikseller için doldurma stratejisi\n)\n\n\n# Veri Artırımı İşleminin Uygulanması\naugmented_data = augmentation.flow(X_train, y_train, batch_size=32)\n\n# İşlem Çıktısı\nprint(\"Data augmentation has been applied to the training set.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T14:21:56.768071Z","iopub.execute_input":"2024-12-20T14:21:56.768555Z","iopub.status.idle":"2024-12-20T14:22:08.228134Z","shell.execute_reply.started":"2024-12-20T14:21:56.768521Z","shell.execute_reply":"2024-12-20T14:22:08.226950Z"}},"outputs":[{"name":"stdout","text":"Data augmentation has been applied to the training set.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **Görüntü Manipülasyonu ve Beyaz Dengesi Düzeltme**\n\nBu betik, görüntü veri setleri üzerinde iki temel işlemi gerçekleştirir:\n\n1. **Görüntü Manipülasyonu** \n   - Parlaklık ve kontrast ayarlarını değiştirerek çeşitli ışıklandırma koşullarını simüle eder.\n   - Manipüle edilmiş görüntüleri belirtilen çıktı dizinine kaydeder.\n\n2. **Beyaz Dengesi Düzeltmesi Uygulama**\n   - Gray World (Gri Dünya) varsayımını kullanarak görüntülerdeki renkleri normalize eder.\n   - RGB kanallarının ortalama yoğunluklarına göre piksel değerlerini ayarlar.\n\n## **Görüntü Manipülasyonu**\n\n### **Genel Bakış**\n`get_manipulated_images` fonksiyonu:\n- Belirtilen giriş dizinindeki tüm görüntüler için parlaklık ve kontrast ayarlarını düzenler.\n- Manipüle edilmiş görüntüleri belirtilen çıktı dizinine kaydeder.\n\n\n### **Anahtar Parametreler**\n- **Parlaklık Faktörü (Brightness Factor)**: Görüntülerin genel parlaklık seviyesini kontrol eder.\n- **Kontrast Faktörü (Contrast Factor)**: Görüntülerdeki koyu ve açık alanlar arasındaki farkı ayarlar.\n","metadata":{}},{"cell_type":"code","source":"# Görüntü Manipülasyonu Fonksiyonu\ndef get_manipulated_images(input_dir, output_dir, brightness_factor=1.5, contrast_factor=1.2):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    for class_name in os.listdir(input_dir):\n        class_path = os.path.join(input_dir, class_name)\n        output_class_path = os.path.join(output_dir, class_name)\n        \n        if not os.path.exists(output_class_path):\n            os.makedirs(output_class_path)\n        \n        for img_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, img_name)\n            img = cv2.imread(img_path)\n            \n            if img is not None:\n                # Parlaklık ve kontrast ayarlamalarını uygulayın\n                manipulated_img = cv2.convertScaleAbs(img, alpha=contrast_factor, beta=brightness_factor * 50)\n                \n                # Düzenlenmiş resmi kaydet\n                save_path = os.path.join(output_class_path, img_name)\n                cv2.imwrite(save_path, manipulated_img)\n    \n    print(f\"Manipulated images saved to {output_dir}\")\n\n# Dosya Yolları Tanımlamaları\ninput_dir = \"/kaggle/working/processed_dataset\"\nmanipulated_dir = \"/kaggle/working/manipulated_images\"\n\n# İşlenmiş görseller üret\nget_manipulated_images(input_dir, manipulated_dir)\n\n\n# Beyaz Dengesi Düzeltme (Gray World Assumption) Fonksiyonu\ndef get_wb_images(input_dir, output_dir):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    for class_name in os.listdir(input_dir):\n        class_path = os.path.join(input_dir, class_name)\n        output_class_path = os.path.join(output_dir, class_name)\n\n        if not os.path.exists(output_class_path):\n            os.makedirs(output_class_path)\n\n        for img_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, img_name)\n            img = cv2.imread(img_path)\n\n            if img is not None:\n                # Beyaz dengesi düzeltmesi için Gri Dünya Varsayımını uygulayın\n                avg_b = np.mean(img[:, :, 0])\n                avg_g = np.mean(img[:, :, 1])\n                avg_r = np.mean(img[:, :, 2])\n                avg_gray = (avg_b + avg_g + avg_r) / 3\n\n                img[:, :, 0] = np.clip(img[:, :, 0] * (avg_gray / avg_b), 0, 255)\n                img[:, :, 1] = np.clip(img[:, :, 1] * (avg_gray / avg_g), 0, 255)\n                img[:, :, 2] = np.clip(img[:, :, 2] * (avg_gray / avg_r), 0, 255)\n\n                # Düzeltilen görüntüyü kaydet\n                save_path = os.path.join(output_class_path, img_name)\n                cv2.imwrite(save_path, img.astype(np.uint8))\n\n    print(f\"White-balanced images saved to {output_dir}\")\n\n# Dosya Yolları Tanımlamaları\nwb_output_dir = \"/kaggle/working/wb_corrected_images\"\n\n# Gri Dünya Varsayımını Uygula\nget_wb_images(manipulated_dir, wb_output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T14:31:08.382872Z","iopub.execute_input":"2024-12-20T14:31:08.383552Z","iopub.status.idle":"2024-12-20T14:31:19.691127Z","shell.execute_reply.started":"2024-12-20T14:31:08.383509Z","shell.execute_reply":"2024-12-20T14:31:19.690039Z"}},"outputs":[{"name":"stdout","text":"Manipulated images saved to /kaggle/working/manipulated_images\nWhite-balanced images saved to /kaggle/working/wb_corrected_images\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# **İşlenmiş ve Beyaz Dengeli Veri Kümelerinin Yüklenmesi**\n\nBu bölüm, işlenmiş ve beyaz dengeli veri kümelerinin eğitim veya değerlendirmede daha fazla kullanım için nasıl yükleneceğini gösterir.","metadata":{}},{"cell_type":"code","source":"# Yolların tanımlanması\nmanipulated_dir = \"/kaggle/working/manipulated_images\"  # İşlenmiş veri kümesi dizini\nwb_output_dir = \"/kaggle/working/wb_corrected_images\"  # Beyaz dengeli veri kümesi dizini\n\n# İşlenmiş veri kümesinin yüklenmesi\nX_manipulated_train, y_manipulated_train = get_manipulated_images(manipulated_dir, manipulated_images)\nprint(f\"Manipulated dataset loaded: {X_manipulated_train.shape}, {y_manipulated_train.shape}\")\n\n# Beyaz dengeli veri kümesinin yüklenmesi\nX_wb_train, y_wb_train = get_wb_images(wb_output_dir, wb_corrected_images)\nprint(f\"White-balanced dataset loaded: {X_wb_train.shape}, {y_wb_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T14:32:34.152289Z","iopub.execute_input":"2024-12-20T14:32:34.152683Z","iopub.status.idle":"2024-12-20T14:32:45.821158Z","shell.execute_reply.started":"2024-12-20T14:32:34.152641Z","shell.execute_reply":"2024-12-20T14:32:45.820240Z"}},"outputs":[{"name":"stdout","text":"Manipulated dataset loaded: (6500, 128, 128, 3), (6500,)\nWhite-balanced dataset loaded: (6500, 128, 128, 3), (6500,)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# **Veri Kümelerini Birleştirme ve Modeli Eğitme**\n\nBu bölüm, veri kümelerini (orijinal, işlenmiş ve beyaz dengeli) birleştirme ve birleştirilmiş veriler üzerinde bir CNN modeli eğitme sürecini gösterir.\n\n---\n\n## **Veri Kümelerini Birleştirme**\n\n### **Genel Bakış**\n- Orijinal, işlenmiş ve beyaz dengeli veri kümeleri tek bir veri kümesinde birleştirilir.\n- Modelin çeşitli veri dağıtımlarından öğrenmesini sağlar.\n\n### **Kod**\n```python\n# Orijinal, İşlenmiş ve Beyaz Dengeli Veri Kümelerini Birleştirme\nX_combined_train = np.concatenate([X_train, X_manipulated_train, X_wb_train], axis=0)\ny_combined_train = np.concatenate([y_train, y_manipulated_train, y_wb_train], axis=0)\n","metadata":{}},{"cell_type":"code","source":"# Gerekli Kütüphanelerin İçe Aktarılması\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, LeakyReLU, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.utils import shuffle\n\n# Orijinal, İşlenmiş ve Beyaz Dengeli Veri Kümelerinin Birleştirilmesi\nX_combined_train = np.concatenate([X_train, X_manipulated_train, X_wb_train], axis=0)\ny_combined_train = np.concatenate([y_train, y_manipulated_train, y_wb_train], axis=0)\n\n# Etiketlerin Bir Hot Codinge Dönüştürülmesi\ny_combined_train_one_hot = to_categorical(y_combined_train, num_classes=10)\ny_test_one_hot = to_categorical(y_test, num_classes=10)\n\n# Birleştirilmiş Veri Setinin Karıştırılması\nX_combined_train, y_combined_train_one_hot = shuffle(X_combined_train, y_combined_train_one_hot, random_state=42)\n\n# CNN Modelin Tanımlanması\nmodel = Sequential([\n    Input(shape=(128, 128, 3)),\n    Conv2D(32, (3, 3)),\n    LeakyReLU(negative_slope=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(64, (3, 3)),\n    LeakyReLU(negative_slope=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(128, (3, 3)),\n    LeakyReLU(negative_slope=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(256, (3, 3)),\n    LeakyReLU(negative_slope=0.1),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Flatten(),\n    Dense(128, kernel_regularizer=l2(0.02)),\n    LeakyReLU(negative_slope=0.1),\n    Dropout(0.7),\n    Dense(10, activation='softmax')  # 10 classes\n])\n\n# Modelin Derlenmesi\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Modelin Eğitilmesi\nhistory = model.fit(\n    X_combined_train, y_combined_train_one_hot,\n    epochs=20,  # Increased epochs\n    batch_size=32,\n    validation_data=(X_test, y_test_one_hot)\n)\n\n# Modelin Özeti\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T14:32:47.105500Z","iopub.execute_input":"2024-12-20T14:32:47.105898Z","iopub.status.idle":"2024-12-20T17:34:35.745720Z","shell.execute_reply.started":"2024-12-20T14:32:47.105843Z","shell.execute_reply":"2024-12-20T17:34:35.743038Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 991ms/step - accuracy: 0.2678 - loss: 7.2221 - val_accuracy: 0.4728 - val_loss: 5.4394\nEpoch 2/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 981ms/step - accuracy: 0.4602 - loss: 5.2359 - val_accuracy: 0.6313 - val_loss: 4.0120\nEpoch 3/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 972ms/step - accuracy: 0.5506 - loss: 4.0436 - val_accuracy: 0.6703 - val_loss: 3.1654\nEpoch 4/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 981ms/step - accuracy: 0.6025 - loss: 3.1812 - val_accuracy: 0.7031 - val_loss: 2.5174\nEpoch 5/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 986ms/step - accuracy: 0.6756 - loss: 2.4854 - val_accuracy: 0.7144 - val_loss: 2.1081\nEpoch 6/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 973ms/step - accuracy: 0.7256 - loss: 1.9903 - val_accuracy: 0.8062 - val_loss: 1.5740\nEpoch 7/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 972ms/step - accuracy: 0.7822 - loss: 1.6121 - val_accuracy: 0.8487 - val_loss: 1.3182\nEpoch 8/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 998ms/step - accuracy: 0.8291 - loss: 1.3027 - val_accuracy: 0.8503 - val_loss: 1.1331\nEpoch 9/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 961ms/step - accuracy: 0.8711 - loss: 1.0795 - val_accuracy: 0.8656 - val_loss: 1.0196\nEpoch 10/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 966ms/step - accuracy: 0.8966 - loss: 0.9152 - val_accuracy: 0.9128 - val_loss: 0.8201\nEpoch 11/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 974ms/step - accuracy: 0.9188 - loss: 0.7835 - val_accuracy: 0.9062 - val_loss: 0.7655\nEpoch 12/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 983ms/step - accuracy: 0.9294 - loss: 0.6998 - val_accuracy: 0.9056 - val_loss: 0.7211\nEpoch 13/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 977ms/step - accuracy: 0.9444 - loss: 0.6123 - val_accuracy: 0.9210 - val_loss: 0.6426\nEpoch 14/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 977ms/step - accuracy: 0.9532 - loss: 0.5499 - val_accuracy: 0.9533 - val_loss: 0.5353\nEpoch 15/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 1s/step - accuracy: 0.9501 - loss: 0.5264 - val_accuracy: 0.9195 - val_loss: 0.5986\nEpoch 16/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 972ms/step - accuracy: 0.9553 - loss: 0.4968 - val_accuracy: 0.9472 - val_loss: 0.5189\nEpoch 17/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 981ms/step - accuracy: 0.9668 - loss: 0.4538 - val_accuracy: 0.9436 - val_loss: 0.5031\nEpoch 18/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 970ms/step - accuracy: 0.9689 - loss: 0.4276 - val_accuracy: 0.9451 - val_loss: 0.4911\nEpoch 19/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 976ms/step - accuracy: 0.9668 - loss: 0.4287 - val_accuracy: 0.9456 - val_loss: 0.4801\nEpoch 20/20\n\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 989ms/step - accuracy: 0.9682 - loss: 0.4174 - val_accuracy: 0.9492 - val_loss: 0.4589\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,179,776\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,776</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,712,288\u001b[0m (17.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,712,288</span> (17.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,570,442\u001b[0m (5.99 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,570,442</span> (5.99 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,140,886\u001b[0m (11.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,140,886</span> (11.98 MB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# **Modelin İşlenmiş Test Setinde Değerlendirilmesi**\n\n## **Genel Bakış**\nBu bölüm, parlaklık ve kontrast ayarlamaları içeren görüntüler içeren işlenmiş test setindeki modelin performansını değerlendirir. Amaç, modelin değiştirilmiş ışık koşullarına ne kadar iyi genelleştirildiğini değerlendirmektir.\n\n## **Adımlar**\n\n### **1. İşlenmiş Test Setini Yükle**\n- İşlenmiş veri seti belirtilen dizinden yüklenir.\n- Görüntüler ve etiketler çıkarılır.\n\n#### **Kod**\n```python\nmanipulated_dir = \"/kaggle/working/manipulated_images\" # Gerektiği gibi yolu ayarlayın\n\n# İşlenmiş test görüntülerini ve etiketlerini yükleyin\nX_manipulated_test, y_manipulated_test = load_images_from_directory(manipulated_dir, selected_classes)\nprint(f\"Manipulated Test Set Loaded: {X_manipulated_test.shape}, {y_manipulated_test.shape}\")","metadata":{}},{"cell_type":"code","source":"# Yüklenen manipüle edilmiş test seti\nmanipulated_dir = \"/kaggle/working/manipulated_images\"  # Gerektiği gibi yolu ayarlayın\n\n# İşlenmiş test görüntülerinin ve etiketlerinin yüklenmesi\nX_manipulated_test, y_manipulated_test = load_images_from_directory(manipulated_dir, selected_classes)\n\nprint(f\"Manipulated Test Set Loaded: {X_manipulated_test.shape}, {y_manipulated_test.shape}\")\n\n# İşlenmiş test etiketlerini tek sıcak kodlamaya dönüştür\ny_manipulated_test_one_hot = to_categorical(y_manipulated_test, num_classes=10)\n\n# Modeli manipüle edilmiş test kümesinde değerlendirin\nmanipulated_loss, manipulated_accuracy = model.evaluate(X_manipulated_test, y_manipulated_test_one_hot, verbose=2)\nprint(f\"Manipulated Test Loss: {manipulated_loss}, Manipulated Test Accuracy: {manipulated_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T17:36:26.155775Z","iopub.execute_input":"2024-12-20T17:36:26.156198Z","iopub.status.idle":"2024-12-20T17:37:20.719580Z","shell.execute_reply.started":"2024-12-20T17:36:26.156162Z","shell.execute_reply":"2024-12-20T17:37:20.718493Z"}},"outputs":[{"name":"stdout","text":"Manipulated Test Set Loaded: (6500, 128, 128, 3), (6500,)\n204/204 - 40s - 198ms/step - accuracy: 0.9895 - loss: 0.3466\nManipulated Test Loss: 0.3465944528579712, Manipulated Test Accuracy: 0.9895384907722473\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# **Beyaz Dengeli Test Setinde Modelin Değerlendirilmesi**\n\n## **Genel Bakış**\nBu bölüm, renk normalizasyonu için Gri Dünya varsayımı kullanılarak işlenen beyaz dengeli test setindeki modelin performansını değerlendirir Modelin amacı beyaz dengesi düzeltmesinin sınıflandırma doğruluğunu iyileştirip iyileştirmediğini belirlemektir.\n\n## **Adımlar**\n\n### **1. Beyaz Dengeli Test Setini Yükle**\n- Beyaz dengeli veri seti belirtilen dizinden yüklenir.\n- Görüntüler ve etiketler çıkarılır.\n\n#### **Kod**\n```python\nwb_output_dir = \"/kaggle/working/wb_corrected_images\" # Yolu gerektiği gibi ayarlayın\n\n# Beyaz dengeli test görüntüleri ve etiketleri yükleyin\nX_wb_test, y_wb_test = load_images_from_directory(wb_output_dir, selected_classes)\nprint(f\"White-Balanced Test Set Loaded: {X_wb_test.shape}, {y_wb_test.shape}\")\n","metadata":{}},{"cell_type":"code","source":"# Beyaz dengesi sağlanmış test setinin yüklenmesi\nwb_output_dir = \"/kaggle/working/wb_corrected_images\"  # Gerektiği gibi yolu ayarlayın\n\n# Beyaz dengesi sağlanmış test görüntülerin ve etiketlerin yüklenmesi\nX_wb_test, y_wb_test = load_images_from_directory(wb_output_dir, selected_classes)\n\nprint(f\"White-Balanced Test Set Loaded: {X_wb_test.shape}, {y_wb_test.shape}\")\n\ny_wb_test_one_hot = to_categorical(y_wb_test, num_classes=10)\n\nwb_loss, wb_accuracy = model.evaluate(X_wb_test, y_wb_test_one_hot, verbose=2)\nprint(f\"White-Balanced Test Loss: {wb_loss}, White-Balanced Test Accuracy: {wb_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T17:38:14.317278Z","iopub.execute_input":"2024-12-20T17:38:14.317676Z","iopub.status.idle":"2024-12-20T17:39:02.055275Z","shell.execute_reply.started":"2024-12-20T17:38:14.317640Z","shell.execute_reply":"2024-12-20T17:39:02.053977Z"}},"outputs":[{"name":"stdout","text":"White-Balanced Test Set Loaded: (6500, 128, 128, 3), (6500,)\n204/204 - 40s - 195ms/step - accuracy: 0.9966 - loss: 0.3308\nWhite-Balanced Test Loss: 0.33081671595573425, White-Balanced Test Accuracy: 0.9966154098510742\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# **Modelin Orijinal Test Setinde Değerlendirilmesi**\n\n## **Genel Bakış**\nBu adımda, bir temel performans belirlemek için modelin orijinal (değiştirilmemiş) test veri setindeki performansını değerlendiriyoruz.\n\n## **Adımlar**\n\n### **1. Etiketleri Tek Sıcak Kodlamaya Dönüştür**\n- Etiketler, kategorik sınıflandırma modeliyle uyumluluk için tek sıcak kodlanmış bir biçime dönüştürülür.\n\n#### **Kod**\n```python\n# Orijinal test etiketlerini tek sıcak kodlamaya dönüştür\n\ny_test_one_hot = to_categorical(y_test, num_classes=10)\n","metadata":{}},{"cell_type":"code","source":"# Orijinal test etiketlerini tek hot codinge dönüştür\ny_test_one_hot = to_categorical(y_test, num_classes=10)\n\n# Modeli orijinal test setinde değerlendirin\noriginal_loss, original_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=2)\n\n# Sonuçların Çıktısı\nprint(f\"Original Test Loss: {original_loss}, Original Test Accuracy: {original_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T17:40:12.521466Z","iopub.execute_input":"2024-12-20T17:40:12.521937Z","iopub.status.idle":"2024-12-20T17:40:26.393553Z","shell.execute_reply.started":"2024-12-20T17:40:12.521899Z","shell.execute_reply":"2024-12-20T17:40:26.392743Z"}},"outputs":[{"name":"stdout","text":"61/61 - 12s - 195ms/step - accuracy: 0.9492 - loss: 0.4589\nOriginal Test Loss: 0.4589402675628662, Original Test Accuracy: 0.9492307901382446\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# **Test Seti Performanslarının Karşılaştırılması ve Raporlanması**\n\n## **Amaç**\nAmaç, modelin performansını üç farklı test veri setinde değerlendirmekti:\n1. **Orijinal Test Seti**\n2. **Manipüle Edilmiş Test Seti**\n3. **Beyaz Dengeli Test Seti**\n\n## **Sonuç Özeti**\n| Test Seti | Doğruluk | Kayıp |\n|---------------------------|-----------|----------|\n| **Orijinal Test Seti** | **%94,92** | 0,4589 |\n| **Manipüle Edilmiş Test Seti** | **%98,95** | 0,3466 |\n| **Beyaz Dengeli Test Seti** | **%99,66** | 0,3308 |\n\n## **Görüşler**\n1. **Orijinal Test Seti**:\n- Model, orijinal veri setinde iyi performans göstererek **%94,92** doğruluk elde ediyor.\n- Bu, modelin eğitim dağılımından verileri doğru şekilde sınıflandırma yeteneğini gösteriyor.\n\n2. **İşlenmiş Test Seti**:\n- Parlaklık ve kontrast ayarlamalarıyla model, **%98,95** oranında iyileştirilmiş bir doğruluk elde ediyor.\n- Bu, modelin sağlam özellikleri öğrendiğini ve görsel olarak değiştirilmiş verilere iyi genelleme yaptığını gösteriyor.\n\n3. **Beyaz Dengeli Test Seti**:\n- Beyaz dengesi düzeltmesi için Gri Dünya varsayımının uygulanması, doğruluğu **%99,66**'ya çıkarıyor.\n- Bu, normalizasyonun modelin görüntü özelliklerinin yorumlanabilirliğini artırmadaki etkinliğini gösteriyor.\n\n## **İyileştirme Önerileri**\n### **Farklı Yapılabilecek Şeyler**\nBu boru hattını geliştirdiğimden beri (veya biz geliştirdiğimizden beri), alternatif yaklaşımların keşfedilebileceği birkaç alan şunlardır:\n\n1. **Model Geliştirmeleri**:\n- ResNet veya EfficientNet gibi önceden eğitilmiş modeller kullanmak eğitimi hızlandırabilir ve sonuçları daha da iyileştirebilirdi.\n- Modele SE blokları veya CBAM gibi dikkat mekanizmaları eklemek, özellik çıkarmayı iyileştirebilirdi.\n\n2. **Veri Hazırlama**:\n- Rastgele gürültü enjeksiyonu veya afin dönüşümler gibi daha çeşitli artırma tekniklerinin uygulanması, gerçek dünya değişkenliğini daha iyi simüle edebilirdi.\n- Diğer renk düzeltme algoritmalarıyla (örneğin, Histogram Eşitleme) test etmek ek içgörüler sağlayabilirdi.\n\n3. **Hiperparametre Optimizasyonu**:\n- Optuna veya HyperOpt gibi kütüphanelerle sistematik hiperparametre ayarlaması yapmak daha iyi yapılandırmalar sağlayabilirdi. - Momentumlu SGD veya uyarlanabilir optimize ediciler (örn. AdamW) gibi optimize edicilerle denemeler yapmak performansı daha da iyi ayarlayabilirdi.\n\n4. **Değerlendirme**:\n- Çapraz doğrulama, sonuçların veri kümesinin farklı bölümlerinde tutarlı olduğundan emin olmak için kullanılabilirdi.\n- Modeli tamamen görülmemiş veri kümelerinde test etmek, gerçek dünyadaki uygulanabilirliği hakkında daha iyi bir anlayış sağlayabilirdi.\n\n### **Puanlar Düşük Olsaydı (<%50)**\nDoğruluk önemli ölçüde daha düşük olsaydı, atılabilecek adımlar şunlardır:\n- **Model Basitleştirme**: Mimariyi basitleştirerek veya bırakma katmanları ekleyerek aşırı uyumu azaltma.\n- **Arttırma**: Aşırı uyumu önlemek ve genellemeyi iyileştirmek için daha agresif artırmalar sunma.\n- **İnce Ayar**: Transfer öğrenimi kullanılarak daha küçük bir veri kümesinde eğitim vermek, daha güçlü bir temel oluşturmaya yardımcı olabilirdi.\n\n## **Sonuç**\nModel, tüm test setlerinde yüksek doğruluk elde ederek olağanüstü bir genelleme gösteriyor. Ancak mimari, veri ön işleme ve hiperparametre ayarlamalarındaki iyileştirmeler, performansı daha da ileriye taşıyabilirdi. Beyaz dengesi düzeltmesinin etkili bir iyileştirme olduğu kanıtlandı ve test doğruluğunu önemli ölçüde artırdı. Bu deney, benzer görevlerin gelecekteki yinelemeleri için sağlam bir temel oluşturuyor.","metadata":{}}]}