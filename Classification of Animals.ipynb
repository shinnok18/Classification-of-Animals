{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Veri Seti Hazırlama Süreci**\n",
    "Bu betik, veri setini eğitim için hazırlamak amacıyla aşağıdaki adımları gerçekleştirir:\n",
    "\n",
    "1. **Veri Seti Dizini ve Sınıf Seçimi**\n",
    "* Veri Seti Dizinleri:\n",
    "Girdi, çıktı ve işlenmiş veri dizinlerini tanımlar.\n",
    "* Sınıf Seçimi:\n",
    "Projede kullanılacak hayvan sınıflarını belirler.\n",
    "\n",
    "2. **Görüntü Sınırları ve Ön İşleme Ayarları**\n",
    "* Sınıf Başına Görüntü Sınırı:\n",
    "Her sınıf için maksimum 650 görüntü ile sınırlandırır.\n",
    "* Görüntü Boyutlandırma:\n",
    "Görüntüleri yeniden boyutlandırmak için hedef boyutu (örneğin, 128x128 piksel) ayarlar.\n",
    "\n",
    "3. **Çıktı Dizinlerinin Kurulumu**\n",
    "* Mevcut Dizinlerin Temizlenmesi:\n",
    "Çıktı ve işlenmiş veri dizinlerini temizleyerek işlem öncesi temiz bir başlangıç sağlar.\n",
    "* Yeni Dizinlerin Oluşturulması:\n",
    "İşlenmiş görüntülerin kaydedilmesi için gerekli olan dizinleri yeniden oluşturur.\n",
    "\n",
    "4. **Görüntü Kopyalama ve İşleme**\n",
    "* Sınıflar Arasında Yineleme:\n",
    "Belirtilen hayvan sınıfları arasında döngü yapar.\n",
    "* Görüntülerin Çıktı Dizinine Kopyalanması:\n",
    "Her sınıf için belirtilen sınıra kadar olan görüntüleri çıktı dizinine kopyalar.\n",
    "* Görüntülerin İşlenmesi:\n",
    "Görüntüleri yeniden boyutlandırır ve normalleştirerek işlenmiş dizine kaydeder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:19:43.285586Z",
     "iopub.status.busy": "2024-12-20T14:19:43.285276Z",
     "iopub.status.idle": "2024-12-20T14:21:11.232220Z",
     "shell.execute_reply": "2024-12-20T14:21:11.230824Z",
     "shell.execute_reply.started": "2024-12-20T14:19:43.285560Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classes and the first 650 images have been copied to '/kaggle/working/selected_animals_dataset', and processed images saved to '/kaggle/working/processed_dataset'.\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneleri içe aktar\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Veri seti dizinleri (Dosya yapınıza göre ayarlayın)\n",
    "data_dir = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\n",
    "output_dir = \"/kaggle/working/selected_animals_dataset\"\n",
    "processed_dir = \"/kaggle/working/processed_dataset\"\n",
    "\n",
    "# Seçilen hayvan sınıfları\n",
    "selected_classes = [\n",
    "    \"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n",
    "    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"\n",
    "]\n",
    "\n",
    "# Her sınıf için maksimum görüntü sayısı\n",
    "max_images_per_class = 650\n",
    "\n",
    "# İstenen görüntü boyutu\n",
    "image_size = (128, 128)  # Model girdi boyutuna göre ayarlanabilir\n",
    "\n",
    "# Çıktı ve işlenmiş dizinleri temizle ve yeniden oluştur\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "if os.path.exists(processed_dir):\n",
    "    shutil.rmtree(processed_dir)\n",
    "os.makedirs(processed_dir)\n",
    "\n",
    "# Seçilen sınıfların görüntülerini kopyala ve işle\n",
    "for animal_class in selected_classes:\n",
    "    class_path = os.path.join(data_dir, animal_class)\n",
    "    if os.path.exists(class_path):\n",
    "        images = sorted(os.listdir(class_path))[:max_images_per_class]\n",
    "        output_class_path = os.path.join(output_dir, animal_class)\n",
    "        processed_class_path = os.path.join(processed_dir, animal_class)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        os.makedirs(processed_class_path, exist_ok=True)\n",
    "\n",
    "        for image in images:\n",
    "            source_path = os.path.join(class_path, image)\n",
    "            target_path = os.path.join(output_class_path, image)\n",
    "            shutil.copy2(source_path, target_path)\n",
    "\n",
    "            # Load image, resize and normalize\n",
    "            img = cv2.imread(source_path)\n",
    "            if img is not None:\n",
    "                img_resized = cv2.resize(img, image_size)\n",
    "                img_normalized = img_resized / 255.0\n",
    "                processed_image_path = os.path.join(processed_class_path, image)\n",
    "                cv2.imwrite(processed_image_path, (img_normalized * 255).astype(np.uint8))\n",
    "\n",
    "print(f\"Selected classes and the first {max_images_per_class} images have been copied to '{output_dir}', and processed images saved to '{processed_dir}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Eğitim ve Test Verilerinin Hazırlanması**\n",
    "Bu betik, veri setini eğitim ve test için hazırlamak amacıyla aşağıdaki işlemleri gerçekleştirir:\n",
    "\n",
    "1. **Veri Seti ve Etiketlerin Tanımlanması**\n",
    "* İşlenmiş Veri Seti Dizini:\n",
    "İşlenmiş veri seti dizinini tanımlar.\n",
    "* Hayvan Sınıfları ve Etiketler:\n",
    "Seçilen hayvan sınıflarını listeler ve bu sınıfları sayısal etiketlere dönüştürür.\n",
    "\n",
    "2. **Veri Yükleme ve Normalizasyon**\n",
    "* Görüntülerin İşlenmesi:\n",
    "Her seçilen sınıf için işlenmiş görüntüler üzerinde iterasyon yapar.\n",
    "* Piksel Değerlerinin Normalizasyonu:\n",
    "Görüntülerin piksel değerlerini [0, 1] aralığına dönüştürür.\n",
    "\n",
    "3. **Verilerin Dönüştürülmesi**\n",
    "* NumPy Dönüşümü:\n",
    "Görüntü ve etiket listelerini modelle uyumlu hale getirmek için NumPy dizilerine dönüştürür.\n",
    "\n",
    "4. **Veri Setinin Bölünmesi**\n",
    "* Eğitim ve Test Ayrımı:\n",
    "Veri setini %70 eğitim ve %30 test olacak şekilde böler.\n",
    "* Rastgelelik Kontrolü:\n",
    "Sabit bir rastgelelik tohumu kullanarak bölünmenin reproducible (tekrarlanabilir) olmasını sağlar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:21:23.797272Z",
     "iopub.status.busy": "2024-12-20T14:21:23.796884Z",
     "iopub.status.idle": "2024-12-20T14:21:31.476292Z",
     "shell.execute_reply": "2024-12-20T14:21:31.475088Z",
     "shell.execute_reply.started": "2024-12-20T14:21:23.797239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split into training and testing sets.\n",
      "Train size: 4550, Test size: 1950\n"
     ]
    }
   ],
   "source": [
    "# Gerekli Kütüphanelerin İçe Aktarılması\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# İşlenmiş Veri Seti Dizini\n",
    "processed_dir = \"/kaggle/working/processed_dataset\"\n",
    "\n",
    "# Seçilen Hayvan Sınıfları\n",
    "selected_classes = [\n",
    "    \"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n",
    "    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"\n",
    "]\n",
    "\n",
    "# Veri ve Etiketlerin Hazırlanması\n",
    "X = []  # Images\n",
    "y = []  # Labels\n",
    "class_mapping = {cls: idx for idx, cls in enumerate(selected_classes)}\n",
    "\n",
    "# Görüntülerin Yüklenmesi ve Normalize Edilmesi\n",
    "for animal_class in selected_classes:\n",
    "    class_path = os.path.join(processed_dir, animal_class)\n",
    "    if os.path.exists(class_path):\n",
    "        images = sorted(os.listdir(class_path))\n",
    "\n",
    "        for image in images:\n",
    "            source_path = os.path.join(class_path, image)\n",
    "\n",
    "            # Load image and normalize (already resized)\n",
    "            img = cv2.imread(source_path)\n",
    "            if img is not None:\n",
    "                img_normalized = img / 255.0\n",
    "                X.append(img_normalized)\n",
    "                y.append(class_mapping[animal_class])\n",
    "\n",
    "# Verilerin NumPy Dizilerine Dönüştürülmesi\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Veri Setinin Eğitim ve Test Olarak Ayrılması\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Bilgilendirme Çıktısı\n",
    "print(f\"Data has been split into training and testing sets.\\nTrain size: {len(X_train)}, Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Eğitim Verileri İçin Veri Artırımı (Data Augmentation)**\n",
    "1. **Veri Artırımı Başlatılması**\n",
    "* ImageDataGenerator sınıfının bir örneği, aşağıdaki veri artırımı seçenekleriyle oluşturulur:\n",
    "* **Döndürme (Rotation):** ±20 derece arasında rastgele döndürme.\n",
    "* **Yatay ve Dikey Kaydırma:** Görüntüleri toplam genişliğin veya yüksekliğin %20'si kadar rastgele kaydırma.\n",
    "* **Kesme Dönüşümleri (Shear Transformations):** Rastgele kesme dönüşümleri uygulanması.\n",
    "* **Yakınlaştırma (Zoom):** Görüntülere %20 oranında rastgele yakınlaştırma.\n",
    "* **Yatay Çevirme (Horizontal Flip):** Görüntüleri yatay eksende rastgele çevirme.\n",
    "* **Doldurma Modu (Fill Mode):** Dönüşümler sonrası oluşan boş piksellerin nasıl doldurulacağını belirtir.\n",
    "\n",
    "2. **Veri Artırımı Uygulanması**\n",
    "* Eğitim görüntüleri (X_train) ve bunlara karşılık gelen etiketler (y_train), 32 görüntülük partiler halinde artırılır.\n",
    "\n",
    "3. **Çıktı**\n",
    "* Eğitim verilerine veri artırımı işleminin başarıyla uygulandığı doğrulanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:21:56.768555Z",
     "iopub.status.busy": "2024-12-20T14:21:56.768071Z",
     "iopub.status.idle": "2024-12-20T14:22:08.228134Z",
     "shell.execute_reply": "2024-12-20T14:22:08.226950Z",
     "shell.execute_reply.started": "2024-12-20T14:21:56.768521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation has been applied to the training set.\n"
     ]
    }
   ],
   "source": [
    "# Gerekli Kütüphanelerin İçe Aktarılması\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Eğitim Verilerine Veri Artırımı Uygulanması\n",
    "augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Rastgele döndürme\n",
    "    width_shift_range=0.2,  # Yatayda rastgele kaydırma\n",
    "    height_shift_range=0.2,  # Dikeyde rastgele kaydırma\n",
    "    shear_range=0.2,  # Kesme dönüşümleri\n",
    "    zoom_range=0.2,  # Rastgele yakınlaştırma\n",
    "    horizontal_flip=True,  # Rastgele yatay çevirme\n",
    "    fill_mode='nearest'  # Boş pikseller için doldurma stratejisi\n",
    ")\n",
    "\n",
    "\n",
    "# Veri Artırımı İşleminin Uygulanması\n",
    "augmented_data = augmentation.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "# İşlem Çıktısı\n",
    "print(\"Data augmentation has been applied to the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Görüntü Manipülasyonu ve Beyaz Dengesi Düzeltme**\n",
    "\n",
    "Bu betik, görüntü veri setleri üzerinde iki temel işlemi gerçekleştirir:\n",
    "\n",
    "1. **Görüntü Manipülasyonu** \n",
    "   - Parlaklık ve kontrast ayarlarını değiştirerek çeşitli ışıklandırma koşullarını simüle eder.\n",
    "   - Manipüle edilmiş görüntüleri belirtilen çıktı dizinine kaydeder.\n",
    "\n",
    "2. **Beyaz Dengesi Düzeltmesi Uygulama**\n",
    "   - Gray World (Gri Dünya) varsayımını kullanarak görüntülerdeki renkleri normalize eder.\n",
    "   - RGB kanallarının ortalama yoğunluklarına göre piksel değerlerini ayarlar.\n",
    "\n",
    "## **Görüntü Manipülasyonu**\n",
    "\n",
    "### **Genel Bakış**\n",
    "`get_manipulated_images` fonksiyonu:\n",
    "- Belirtilen giriş dizinindeki tüm görüntüler için parlaklık ve kontrast ayarlarını düzenler.\n",
    "- Manipüle edilmiş görüntüleri belirtilen çıktı dizinine kaydeder.\n",
    "\n",
    "\n",
    "### **Anahtar Parametreler**\n",
    "- **Parlaklık Faktörü (Brightness Factor)**: Görüntülerin genel parlaklık seviyesini kontrol eder.\n",
    "- **Kontrast Faktörü (Contrast Factor)**: Görüntülerdeki koyu ve açık alanlar arasındaki farkı ayarlar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:31:08.383552Z",
     "iopub.status.busy": "2024-12-20T14:31:08.382872Z",
     "iopub.status.idle": "2024-12-20T14:31:19.691127Z",
     "shell.execute_reply": "2024-12-20T14:31:19.690039Z",
     "shell.execute_reply.started": "2024-12-20T14:31:08.383509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulated images saved to /kaggle/working/manipulated_images\n",
      "White-balanced images saved to /kaggle/working/wb_corrected_images\n"
     ]
    }
   ],
   "source": [
    "# Görüntü Manipülasyonu Fonksiyonu\n",
    "def get_manipulated_images(input_dir, output_dir, brightness_factor=1.5, contrast_factor=1.2):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        output_class_path = os.path.join(output_dir, class_name)\n",
    "        \n",
    "        if not os.path.exists(output_class_path):\n",
    "            os.makedirs(output_class_path)\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                # Parlaklık ve kontrast ayarlamalarını uygulayın\n",
    "                manipulated_img = cv2.convertScaleAbs(img, alpha=contrast_factor, beta=brightness_factor * 50)\n",
    "                \n",
    "                # Düzenlenmiş resmi kaydet\n",
    "                save_path = os.path.join(output_class_path, img_name)\n",
    "                cv2.imwrite(save_path, manipulated_img)\n",
    "    \n",
    "    print(f\"Manipulated images saved to {output_dir}\")\n",
    "\n",
    "# Dosya Yolları Tanımlamaları\n",
    "input_dir = \"/kaggle/working/processed_dataset\"\n",
    "manipulated_dir = \"/kaggle/working/manipulated_images\"\n",
    "\n",
    "# İşlenmiş görseller üret\n",
    "get_manipulated_images(input_dir, manipulated_dir)\n",
    "\n",
    "\n",
    "# Beyaz Dengesi Düzeltme (Gray World Assumption) Fonksiyonu\n",
    "def get_wb_images(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        output_class_path = os.path.join(output_dir, class_name)\n",
    "\n",
    "        if not os.path.exists(output_class_path):\n",
    "            os.makedirs(output_class_path)\n",
    "\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is not None:\n",
    "                # Beyaz dengesi düzeltmesi için Gri Dünya Varsayımını uygulayın\n",
    "                avg_b = np.mean(img[:, :, 0])\n",
    "                avg_g = np.mean(img[:, :, 1])\n",
    "                avg_r = np.mean(img[:, :, 2])\n",
    "                avg_gray = (avg_b + avg_g + avg_r) / 3\n",
    "\n",
    "                img[:, :, 0] = np.clip(img[:, :, 0] * (avg_gray / avg_b), 0, 255)\n",
    "                img[:, :, 1] = np.clip(img[:, :, 1] * (avg_gray / avg_g), 0, 255)\n",
    "                img[:, :, 2] = np.clip(img[:, :, 2] * (avg_gray / avg_r), 0, 255)\n",
    "\n",
    "                # Düzeltilen görüntüyü kaydet\n",
    "                save_path = os.path.join(output_class_path, img_name)\n",
    "                cv2.imwrite(save_path, img.astype(np.uint8))\n",
    "\n",
    "    print(f\"White-balanced images saved to {output_dir}\")\n",
    "\n",
    "# Dosya Yolları Tanımlamaları\n",
    "wb_output_dir = \"/kaggle/working/wb_corrected_images\"\n",
    "\n",
    "# Gri Dünya Varsayımını Uygula\n",
    "get_wb_images(manipulated_dir, wb_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **İşlenmiş ve Beyaz Dengeli Veri Kümelerinin Yüklenmesi**\n",
    "\n",
    "Bu bölüm, işlenmiş ve beyaz dengeli veri kümelerinin eğitim veya değerlendirmede daha fazla kullanım için nasıl yükleneceğini gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:32:34.152683Z",
     "iopub.status.busy": "2024-12-20T14:32:34.152289Z",
     "iopub.status.idle": "2024-12-20T14:32:45.821158Z",
     "shell.execute_reply": "2024-12-20T14:32:45.820240Z",
     "shell.execute_reply.started": "2024-12-20T14:32:34.152641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulated dataset loaded: (6500, 128, 128, 3), (6500,)\n",
      "White-balanced dataset loaded: (6500, 128, 128, 3), (6500,)\n"
     ]
    }
   ],
   "source": [
    "# Yolların tanımlanması\n",
    "manipulated_dir = \"/kaggle/working/manipulated_images\"  # İşlenmiş veri kümesi dizini\n",
    "wb_output_dir = \"/kaggle/working/wb_corrected_images\"  # Beyaz dengeli veri kümesi dizini\n",
    "\n",
    "# İşlenmiş veri kümesinin yüklenmesi\n",
    "X_manipulated_train, y_manipulated_train = get_manipulated_images(manipulated_dir, manipulated_images)\n",
    "print(f\"Manipulated dataset loaded: {X_manipulated_train.shape}, {y_manipulated_train.shape}\")\n",
    "\n",
    "# Beyaz dengeli veri kümesinin yüklenmesi\n",
    "X_wb_train, y_wb_train = get_wb_images(wb_output_dir, wb_corrected_images)\n",
    "print(f\"White-balanced dataset loaded: {X_wb_train.shape}, {y_wb_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Veri Kümelerini Birleştirme ve Modeli Eğitme**\n",
    "\n",
    "Bu bölüm, veri kümelerini (orijinal, işlenmiş ve beyaz dengeli) birleştirme ve birleştirilmiş veriler üzerinde bir CNN modeli eğitme sürecini gösterir.\n",
    "\n",
    "---\n",
    "\n",
    "## **Veri Kümelerini Birleştirme**\n",
    "\n",
    "### **Genel Bakış**\n",
    "- Orijinal, işlenmiş ve beyaz dengeli veri kümeleri tek bir veri kümesinde birleştirilir.\n",
    "- Modelin çeşitli veri dağıtımlarından öğrenmesini sağlar.\n",
    "\n",
    "### **Kod**\n",
    "```python\n",
    "# Orijinal, İşlenmiş ve Beyaz Dengeli Veri Kümelerini Birleştirme\n",
    "X_combined_train = np.concatenate([X_train, X_manipulated_train, X_wb_train], axis=0)\n",
    "y_combined_train = np.concatenate([y_train, y_manipulated_train, y_wb_train], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:32:47.105898Z",
     "iopub.status.busy": "2024-12-20T14:32:47.105500Z",
     "iopub.status.idle": "2024-12-20T17:34:35.745720Z",
     "shell.execute_reply": "2024-12-20T17:34:35.743038Z",
     "shell.execute_reply.started": "2024-12-20T14:32:47.105843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 991ms/step - accuracy: 0.2678 - loss: 7.2221 - val_accuracy: 0.4728 - val_loss: 5.4394\n",
      "Epoch 2/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 981ms/step - accuracy: 0.4602 - loss: 5.2359 - val_accuracy: 0.6313 - val_loss: 4.0120\n",
      "Epoch 3/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 972ms/step - accuracy: 0.5506 - loss: 4.0436 - val_accuracy: 0.6703 - val_loss: 3.1654\n",
      "Epoch 4/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 981ms/step - accuracy: 0.6025 - loss: 3.1812 - val_accuracy: 0.7031 - val_loss: 2.5174\n",
      "Epoch 5/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 986ms/step - accuracy: 0.6756 - loss: 2.4854 - val_accuracy: 0.7144 - val_loss: 2.1081\n",
      "Epoch 6/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 973ms/step - accuracy: 0.7256 - loss: 1.9903 - val_accuracy: 0.8062 - val_loss: 1.5740\n",
      "Epoch 7/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 972ms/step - accuracy: 0.7822 - loss: 1.6121 - val_accuracy: 0.8487 - val_loss: 1.3182\n",
      "Epoch 8/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 998ms/step - accuracy: 0.8291 - loss: 1.3027 - val_accuracy: 0.8503 - val_loss: 1.1331\n",
      "Epoch 9/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 961ms/step - accuracy: 0.8711 - loss: 1.0795 - val_accuracy: 0.8656 - val_loss: 1.0196\n",
      "Epoch 10/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 966ms/step - accuracy: 0.8966 - loss: 0.9152 - val_accuracy: 0.9128 - val_loss: 0.8201\n",
      "Epoch 11/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 974ms/step - accuracy: 0.9188 - loss: 0.7835 - val_accuracy: 0.9062 - val_loss: 0.7655\n",
      "Epoch 12/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 983ms/step - accuracy: 0.9294 - loss: 0.6998 - val_accuracy: 0.9056 - val_loss: 0.7211\n",
      "Epoch 13/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 977ms/step - accuracy: 0.9444 - loss: 0.6123 - val_accuracy: 0.9210 - val_loss: 0.6426\n",
      "Epoch 14/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 977ms/step - accuracy: 0.9532 - loss: 0.5499 - val_accuracy: 0.9533 - val_loss: 0.5353\n",
      "Epoch 15/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 1s/step - accuracy: 0.9501 - loss: 0.5264 - val_accuracy: 0.9195 - val_loss: 0.5986\n",
      "Epoch 16/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 972ms/step - accuracy: 0.9553 - loss: 0.4968 - val_accuracy: 0.9472 - val_loss: 0.5189\n",
      "Epoch 17/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 981ms/step - accuracy: 0.9668 - loss: 0.4538 - val_accuracy: 0.9436 - val_loss: 0.5031\n",
      "Epoch 18/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 970ms/step - accuracy: 0.9689 - loss: 0.4276 - val_accuracy: 0.9451 - val_loss: 0.4911\n",
      "Epoch 19/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 976ms/step - accuracy: 0.9668 - loss: 0.4287 - val_accuracy: 0.9456 - val_loss: 0.4801\n",
      "Epoch 20/20\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 989ms/step - accuracy: 0.9682 - loss: 0.4174 - val_accuracy: 0.9492 - val_loss: 0.4589\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,776</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,179,776\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,712,288</span> (17.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,712,288\u001b[0m (17.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,570,442</span> (5.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,570,442\u001b[0m (5.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,140,886</span> (11.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,140,886\u001b[0m (11.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gerekli Kütüphanelerin İçe Aktarılması\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Orijinal, İşlenmiş ve Beyaz Dengeli Veri Kümelerinin Birleştirilmesi\n",
    "X_combined_train = np.concatenate([X_train, X_manipulated_train, X_wb_train], axis=0)\n",
    "y_combined_train = np.concatenate([y_train, y_manipulated_train, y_wb_train], axis=0)\n",
    "\n",
    "# Etiketlerin Bir Hot Codinge Dönüştürülmesi\n",
    "y_combined_train_one_hot = to_categorical(y_combined_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Birleştirilmiş Veri Setinin Karıştırılması\n",
    "X_combined_train, y_combined_train_one_hot = shuffle(X_combined_train, y_combined_train_one_hot, random_state=42)\n",
    "\n",
    "# CNN Modelin Tanımlanması\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 128, 3)),\n",
    "    Conv2D(32, (3, 3)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, kernel_regularizer=l2(0.02)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    Dropout(0.7),\n",
    "    Dense(10, activation='softmax')  # 10 classes\n",
    "])\n",
    "\n",
    "# Modelin Derlenmesi\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Modelin Eğitilmesi\n",
    "history = model.fit(\n",
    "    X_combined_train, y_combined_train_one_hot,\n",
    "    epochs=20,  # Increased epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test_one_hot)\n",
    ")\n",
    "\n",
    "# Modelin Özeti\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelin İşlenmiş Test Setinde Değerlendirilmesi**\n",
    "\n",
    "## **Genel Bakış**\n",
    "Bu bölüm, parlaklık ve kontrast ayarlamaları içeren görüntüler içeren işlenmiş test setindeki modelin performansını değerlendirir. Amaç, modelin değiştirilmiş ışık koşullarına ne kadar iyi genelleştirildiğini değerlendirmektir.\n",
    "\n",
    "## **Adımlar**\n",
    "\n",
    "### **1. İşlenmiş Test Setini Yükle**\n",
    "- İşlenmiş veri seti belirtilen dizinden yüklenir.\n",
    "- Görüntüler ve etiketler çıkarılır.\n",
    "\n",
    "#### **Kod**\n",
    "```python\n",
    "manipulated_dir = \"/kaggle/working/manipulated_images\" # Gerektiği gibi yolu ayarlayın\n",
    "\n",
    "# İşlenmiş test görüntülerini ve etiketlerini yükleyin\n",
    "X_manipulated_test, y_manipulated_test = load_images_from_directory(manipulated_dir, selected_classes)\n",
    "print(f\"Manipulated Test Set Loaded: {X_manipulated_test.shape}, {y_manipulated_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T17:36:26.156198Z",
     "iopub.status.busy": "2024-12-20T17:36:26.155775Z",
     "iopub.status.idle": "2024-12-20T17:37:20.719580Z",
     "shell.execute_reply": "2024-12-20T17:37:20.718493Z",
     "shell.execute_reply.started": "2024-12-20T17:36:26.156162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulated Test Set Loaded: (6500, 128, 128, 3), (6500,)\n",
      "204/204 - 40s - 198ms/step - accuracy: 0.9895 - loss: 0.3466\n",
      "Manipulated Test Loss: 0.3465944528579712, Manipulated Test Accuracy: 0.9895384907722473\n"
     ]
    }
   ],
   "source": [
    "# Yüklenen manipüle edilmiş test seti\n",
    "manipulated_dir = \"/kaggle/working/manipulated_images\"  # Gerektiği gibi yolu ayarlayın\n",
    "\n",
    "# İşlenmiş test görüntülerinin ve etiketlerinin yüklenmesi\n",
    "X_manipulated_test, y_manipulated_test = load_images_from_directory(manipulated_dir, selected_classes)\n",
    "\n",
    "print(f\"Manipulated Test Set Loaded: {X_manipulated_test.shape}, {y_manipulated_test.shape}\")\n",
    "\n",
    "# İşlenmiş test etiketlerini tek sıcak kodlamaya dönüştür\n",
    "y_manipulated_test_one_hot = to_categorical(y_manipulated_test, num_classes=10)\n",
    "\n",
    "# Modeli manipüle edilmiş test kümesinde değerlendirin\n",
    "manipulated_loss, manipulated_accuracy = model.evaluate(X_manipulated_test, y_manipulated_test_one_hot, verbose=2)\n",
    "print(f\"Manipulated Test Loss: {manipulated_loss}, Manipulated Test Accuracy: {manipulated_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Beyaz Dengeli Test Setinde Modelin Değerlendirilmesi**\n",
    "\n",
    "## **Genel Bakış**\n",
    "Bu bölüm, renk normalizasyonu için Gri Dünya varsayımı kullanılarak işlenen beyaz dengeli test setindeki modelin performansını değerlendirir Modelin amacı beyaz dengesi düzeltmesinin sınıflandırma doğruluğunu iyileştirip iyileştirmediğini belirlemektir.\n",
    "\n",
    "## **Adımlar**\n",
    "\n",
    "### **1. Beyaz Dengeli Test Setini Yükle**\n",
    "- Beyaz dengeli veri seti belirtilen dizinden yüklenir.\n",
    "- Görüntüler ve etiketler çıkarılır.\n",
    "\n",
    "#### **Kod**\n",
    "```python\n",
    "wb_output_dir = \"/kaggle/working/wb_corrected_images\" # Yolu gerektiği gibi ayarlayın\n",
    "\n",
    "# Beyaz dengeli test görüntüleri ve etiketleri yükleyin\n",
    "X_wb_test, y_wb_test = load_images_from_directory(wb_output_dir, selected_classes)\n",
    "print(f\"White-Balanced Test Set Loaded: {X_wb_test.shape}, {y_wb_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T17:38:14.317676Z",
     "iopub.status.busy": "2024-12-20T17:38:14.317278Z",
     "iopub.status.idle": "2024-12-20T17:39:02.055275Z",
     "shell.execute_reply": "2024-12-20T17:39:02.053977Z",
     "shell.execute_reply.started": "2024-12-20T17:38:14.317640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White-Balanced Test Set Loaded: (6500, 128, 128, 3), (6500,)\n",
      "204/204 - 40s - 195ms/step - accuracy: 0.9966 - loss: 0.3308\n",
      "White-Balanced Test Loss: 0.33081671595573425, White-Balanced Test Accuracy: 0.9966154098510742\n"
     ]
    }
   ],
   "source": [
    "# Beyaz dengesi sağlanmış test setinin yüklenmesi\n",
    "wb_output_dir = \"/kaggle/working/wb_corrected_images\"  # Gerektiği gibi yolu ayarlayın\n",
    "\n",
    "# Beyaz dengesi sağlanmış test görüntülerin ve etiketlerin yüklenmesi\n",
    "X_wb_test, y_wb_test = load_images_from_directory(wb_output_dir, selected_classes)\n",
    "\n",
    "print(f\"White-Balanced Test Set Loaded: {X_wb_test.shape}, {y_wb_test.shape}\")\n",
    "\n",
    "y_wb_test_one_hot = to_categorical(y_wb_test, num_classes=10)\n",
    "\n",
    "wb_loss, wb_accuracy = model.evaluate(X_wb_test, y_wb_test_one_hot, verbose=2)\n",
    "print(f\"White-Balanced Test Loss: {wb_loss}, White-Balanced Test Accuracy: {wb_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelin Orijinal Test Setinde Değerlendirilmesi**\n",
    "\n",
    "## **Genel Bakış**\n",
    "Bu adımda, bir temel performans belirlemek için modelin orijinal (değiştirilmemiş) test veri setindeki performansını değerlendiriyoruz.\n",
    "\n",
    "## **Adımlar**\n",
    "\n",
    "### **1. Etiketleri Tek Sıcak Kodlamaya Dönüştür**\n",
    "- Etiketler, kategorik sınıflandırma modeliyle uyumluluk için tek sıcak kodlanmış bir biçime dönüştürülür.\n",
    "\n",
    "#### **Kod**\n",
    "```python\n",
    "# Orijinal test etiketlerini tek sıcak kodlamaya dönüştür\n",
    "\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T17:40:12.521937Z",
     "iopub.status.busy": "2024-12-20T17:40:12.521466Z",
     "iopub.status.idle": "2024-12-20T17:40:26.393553Z",
     "shell.execute_reply": "2024-12-20T17:40:26.392743Z",
     "shell.execute_reply.started": "2024-12-20T17:40:12.521899Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 12s - 195ms/step - accuracy: 0.9492 - loss: 0.4589\n",
      "Original Test Loss: 0.4589402675628662, Original Test Accuracy: 0.9492307901382446\n"
     ]
    }
   ],
   "source": [
    "# Orijinal test etiketlerini tek hot codinge dönüştür\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Modeli orijinal test setinde değerlendirin\n",
    "original_loss, original_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "\n",
    "# Sonuçların Çıktısı\n",
    "print(f\"Original Test Loss: {original_loss}, Original Test Accuracy: {original_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1408532,
     "sourceId": 2333429,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
